import streamlit as st
from util.FIR_filter import FIRFilter
import numpy as np
import pyaudio
import threading
import sys
from queue import Queue
from streamlit import add_script_run_ctx, get_script_run_ctx

# Queue for thread-safe data transfer
audio_queue = Queue(maxsize=10)  # Set a max size to prevent unbounded growth

# Function to update the plot
def update_plot():
    if not audio_queue.empty():
        data = audio_queue.get()
        chart.line_chart(data)


def calculate_octave_ranges(base_freq, num_octaves, sample_rate):
    octave_ranges = []
    for i in range(num_octaves):
        fmin = base_freq * (2 ** i)  # Minimum frequency for the octave
        fmax = base_freq * (2 ** (i + 1))  # Maximum frequency for the octave

        # Normalize the frequencies
        fmin_normalized = fmin / sample_rate
        fmax_normalized = fmax / sample_rate

        octave_ranges.append((fmin_normalized, fmax_normalized))
    return octave_ranges


# Streamlit initialization
st.title("Real-Time Audio Visualization")

# Placeholders for real-time updates
chart = st.empty()

# Global state to store audio data
if "audio_data" not in st.session_state:
    st.session_state.audio_data = np.zeros(1000)


# Initialize PyAudio
pa = pyaudio.PyAudio()
devices = pa.get_device_count()
print(f"num devices: {devices}")
if devices < 1:
    print(f"num of devices is {devices}. need at least one device")
    sys.exit(1)
sample_rate = 44100  # Adjust as needed
mic_index = -1
for i in range(pa.get_device_count()):
    dev = pa.get_device_info_by_index(i)
    print(f"Device {i}: {dev['name']}")
    # add a device name from the list that you have
    if 'Razer Kiyo' in dev['name']:
        print(f"razr cam has mic, using index {i}")
        mic_index = i
        sample_rate = 16000  # for razer kiyo cam
        break
    if 'sysdefault' in dev['name']:
        print(f"sydef mic, using index {i}")
        mic_index = i
        sample_rate = 48000  # for default mic in most systems
        break

if mic_index == -1:
    print("no mic detected...\nExiting")
    sys.exit(1)

# Sample rate and base frequency
base_freq = 27.5  # Starting frequency of the first octave
# Calculate octave ranges
num_octaves = 7
max_piano_freq = 4096
octave_ranges = calculate_octave_ranges(base_freq, num_octaves, max_piano_freq)
N = 32
# Define a decay time in seconds (adjust as needed)
decay_time = 0.25  # half a second, for example

# Keep track of the last time a note was detected for each filter
last_detection_times = [0] * num_octaves

on_threshold = 3500  # Threshold to turn the indicator on
off_threshold = 100  # Threshold to turn the indicator off
is_note_detected = [False] * num_octaves  # State for each octave

octave_values = np.zeros(num_octaves)  # Initial octave values


# Audio processing function
def process_audio():
    # Define the callback function
    def callback(in_data, frame_count, time_info, status):
        #add_script_run_ctx(threading.current_thread(), ctx)
        audio_data = np.frombuffer(in_data, dtype=np.float32)
        filtered_data = [filter.process(audio_data) for filter in filters]

        for i, data in enumerate(filtered_data):
            if is_note_detected[i]:
                if np.max(np.abs(data)) < off_threshold:
                    # st.write(f"max data on filter {i} off: {np.max(np.abs(data))}")
                    is_note_detected[i] = False
                    octave_values[i] = 0
                else:
                    if np.max(np.abs(data)) > on_threshold:
                        # st.write(f"max data on filter {i} on: {np.max(np.abs(data))}")
                        is_note_detected[i] = True
                        octave_values[i] = 1

        st.session_state.audio_data = audio_data  # Update the global state
        return (in_data, pyaudio.paContinue)

    # Initialize PyAudio and start the stream
    pa = pyaudio.PyAudio()
    # st.write()
    stream = pa.open(format=pyaudio.paInt32,
                     channels=1,
                     rate=sample_rate,
                     input=True,
                     input_device_index=mic_index,
                     stream_callback=callback)

    stream.start_stream()

    while stream.is_active():
        # You could add a sleep here if needed
        pass

    stream.stop_stream()
    stream.close()
    pa.terminate()


# Start the audio processing in a separate thread
audio_thread = threading.Thread(target=process_audio)
audio_thread.start()

# Update the chart in real-time
while True:
    chart.line_chart(st.session_state.audio_data)
